{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from looper import Looper\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from models import CNN_Encoder, RNN_Decoder, image_features_extract_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with the following params:\n",
      "VOCAB_SIZE : 5000\n",
      "BATCH_SIZE : 32\n",
      "BUFFER_SIZE : 5000\n",
      "embedding_dim : 512\n",
      "embedding_words : 300\n",
      "units : 512\n",
      "embedding_size : 5001\n",
      "MAX_LENGTH : 20\n",
      "TOKENIZER_FOLDER : ./tokenizer/\n",
      "TOKENIZER_NAME : spbe_tokenizer.e\n",
      "CHECKPOINT_FOLDER : saved_models\n",
      "## Run set_params to change params ##\n"
     ]
    }
   ],
   "source": [
    "looper = Looper(CNN_Encoder, RNN_Decoder, image_features_extract_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from ./tokenizer/spbe_tokenizer.e\n"
     ]
    }
   ],
   "source": [
    "tokenizer = looper.load_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'VOCAB_SIZE': 5000,\n",
       " 'BATCH_SIZE': 32,\n",
       " 'BUFFER_SIZE': 5000,\n",
       " 'embedding_dim': 512,\n",
       " 'embedding_words': 300,\n",
       " 'units': 512,\n",
       " 'embedding_size': 5001,\n",
       " 'MAX_LENGTH': 20,\n",
       " 'TOKENIZER_FOLDER': './tokenizer/',\n",
       " 'TOKENIZER_NAME': 'spbe_tokenizer.e',\n",
       " 'CHECKPOINT_FOLDER': 'saved_models'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "looper.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with the following params:\n",
      "VOCAB_SIZE : 5000\n",
      "BATCH_SIZE : 32\n",
      "BUFFER_SIZE : 5000\n",
      "embedding_dim : 1024\n",
      "embedding_words : 300\n",
      "units : 1024\n",
      "embedding_size : 5001\n",
      "MAX_LENGTH : 20\n",
      "TOKENIZER_FOLDER : ./tokenizer/\n",
      "TOKENIZER_NAME : spbe_tokenizer.e\n",
      "CHECKPOINT_FOLDER : ./checkpoint_dis/1024_embed\n",
      "## Run set_params to change params ##\n"
     ]
    }
   ],
   "source": [
    "# CHANGE PARAMS\n",
    "\n",
    "params = {'VOCAB_SIZE': 5000,\n",
    " 'BATCH_SIZE': 32,\n",
    " 'BUFFER_SIZE': 5000,\n",
    " 'embedding_dim': 1024,\n",
    " 'embedding_words': 300,\n",
    " 'units': 1024,\n",
    " 'embedding_size': 5001,\n",
    " 'MAX_LENGTH': 20,\n",
    " 'TOKENIZER_FOLDER': './tokenizer/',\n",
    " 'TOKENIZER_NAME': 'spbe_tokenizer.e',\n",
    " 'CHECKPOINT_FOLDER': './checkpoint_dis/1024_embed'}\n",
    "\n",
    "params = looper.set_params(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7eff505789e8>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv('val.csv')\n",
    "captions_val = data.title.to_list()\n",
    "images_val = data.paths.to_list()\n",
    "\n",
    "data = pd.read_csv('train.csv')\n",
    "data['captions'] =  data['captions'].astype(str)\n",
    "data['sent_len'] = data['captions'].apply(lambda r: len(r.split(' ')))\n",
    "data = data[(data['sent_len']<20) & (data['sent_len']>4)]\n",
    "captions_train = data.title.to_list()\n",
    "images_train = data.paths.to_list()\n",
    "data.hist('sent_len')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max title len 20\n",
      "len titles: 2375,len images: 2375\n",
      "captions vector shape (2375, 20)\n",
      "NOT using augmentations in loader\n"
     ]
    }
   ],
   "source": [
    "dataset_val = looper.make_dataset(images_val,captions_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max title len 20\n",
      "len titles: 29254,len images: 29254\n",
      "captions vector shape (29254, 20)\n",
      "Using augmentations in loader\n"
     ]
    }
   ],
   "source": [
    "dataset_train = looper.make_dataset(images_train, captions_train, loader_type='aug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 1.7335\n",
      "Epoch 1 Batch 100 Loss 1.7104\n",
      "Epoch 1 Batch 200 Loss 1.6988\n",
      "Epoch 1 Batch 300 Loss 1.4412\n",
      "Epoch 1 Batch 400 Loss 1.4744\n",
      "Epoch 1 Batch 500 Loss 1.5901\n",
      "Epoch 1 Batch 600 Loss 1.5313\n",
      "Epoch 1 Batch 700 Loss 1.4111\n",
      "Epoch 1 Batch 800 Loss 1.4420\n",
      "Epoch 1 Batch 900 Loss 1.3941\n",
      "precision at | val: 0.2010714340209961, train: 0.20968806365800033\n",
      "Epoch 1 Loss 2.414678\n",
      "Time taken for 1 epoch 387.61447834968567 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.3773\n",
      "Epoch 2 Batch 100 Loss 1.3290\n",
      "Epoch 2 Batch 200 Loss 1.3677\n",
      "Epoch 2 Batch 300 Loss 1.2660\n",
      "Epoch 2 Batch 400 Loss 1.3922\n",
      "Epoch 2 Batch 500 Loss 1.3392\n",
      "Epoch 2 Batch 600 Loss 1.3708\n",
      "Epoch 2 Batch 700 Loss 1.3133\n",
      "Epoch 2 Batch 800 Loss 1.1813\n",
      "Epoch 2 Batch 900 Loss 1.4067\n",
      "Epoch 2 Loss 2.190543\n",
      "Time taken for 1 epoch 251.69899249076843 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.3788\n",
      "Epoch 3 Batch 100 Loss 1.1327\n",
      "Epoch 3 Batch 200 Loss 1.2980\n",
      "Epoch 3 Batch 300 Loss 1.3055\n",
      "Epoch 3 Batch 400 Loss 1.3005\n",
      "Epoch 3 Batch 500 Loss 1.3912\n",
      "Epoch 3 Batch 600 Loss 1.2997\n",
      "Epoch 3 Batch 700 Loss 1.3888\n",
      "Epoch 3 Batch 800 Loss 1.1287\n",
      "Epoch 3 Batch 900 Loss 1.1518\n",
      "Epoch 3 Loss 2.054890\n",
      "Time taken for 1 epoch 251.8905532360077 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.3673\n",
      "Epoch 4 Batch 100 Loss 1.2500\n",
      "Epoch 4 Batch 200 Loss 1.5121\n",
      "Epoch 4 Batch 300 Loss 1.2285\n",
      "Epoch 4 Batch 400 Loss 1.2113\n",
      "Epoch 4 Batch 500 Loss 1.1917\n",
      "Epoch 4 Batch 600 Loss 1.0344\n",
      "Epoch 4 Batch 700 Loss 1.2176\n",
      "Epoch 4 Batch 800 Loss 1.1815\n",
      "Epoch 4 Batch 900 Loss 1.2107\n",
      "precision at | val: 0.17946428934733072, train: 0.17338341884925718\n",
      "Epoch 4 Loss 1.950314\n",
      "Time taken for 1 epoch 367.57357144355774 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.2745\n",
      "Epoch 5 Batch 100 Loss 1.1879\n",
      "Epoch 5 Batch 200 Loss 1.1969\n",
      "Epoch 5 Batch 300 Loss 1.0187\n",
      "Epoch 5 Batch 400 Loss 0.9802\n",
      "Epoch 5 Batch 500 Loss 1.1282\n",
      "Epoch 5 Batch 600 Loss 1.1933\n",
      "Epoch 5 Batch 700 Loss 1.1192\n",
      "Epoch 5 Batch 800 Loss 1.3502\n",
      "Epoch 5 Batch 900 Loss 1.1678\n",
      "Epoch 5 Loss 1.866438\n",
      "Time taken for 1 epoch 250.90717315673828 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 1.1676\n",
      "Epoch 6 Batch 100 Loss 1.1028\n",
      "Epoch 6 Batch 200 Loss 0.9753\n",
      "Epoch 6 Batch 300 Loss 1.0263\n",
      "Epoch 6 Batch 400 Loss 1.0546\n",
      "Epoch 6 Batch 500 Loss 1.2668\n",
      "Epoch 6 Batch 600 Loss 1.0107\n",
      "Epoch 6 Batch 700 Loss 0.9564\n",
      "Epoch 6 Batch 800 Loss 0.9276\n",
      "Epoch 6 Batch 900 Loss 1.1108\n",
      "Epoch 6 Loss 1.792781\n",
      "Time taken for 1 epoch 251.05380702018738 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 1.1452\n",
      "Epoch 7 Batch 100 Loss 0.9784\n",
      "Epoch 7 Batch 200 Loss 1.0348\n",
      "Epoch 7 Batch 300 Loss 1.1928\n",
      "Epoch 7 Batch 400 Loss 1.0625\n",
      "Epoch 7 Batch 500 Loss 1.0745\n",
      "Epoch 7 Batch 600 Loss 1.0931\n",
      "Epoch 7 Batch 700 Loss 1.0209\n",
      "Epoch 7 Batch 800 Loss 1.0256\n",
      "Epoch 7 Batch 900 Loss 1.1515\n",
      "precision at | val: 0.17273810068766277, train: 0.18177368497587945\n",
      "Epoch 7 Loss 1.723135\n",
      "Time taken for 1 epoch 368.6043553352356 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 1.0008\n",
      "Epoch 8 Batch 100 Loss 1.0349\n",
      "Epoch 8 Batch 200 Loss 1.1109\n",
      "Epoch 8 Batch 300 Loss 0.9700\n",
      "Epoch 8 Batch 400 Loss 1.0848\n",
      "Epoch 8 Batch 500 Loss 1.1065\n",
      "Epoch 8 Batch 600 Loss 0.9557\n",
      "Epoch 8 Batch 700 Loss 0.9348\n",
      "Epoch 8 Batch 800 Loss 1.0017\n",
      "Epoch 8 Batch 900 Loss 1.0559\n",
      "Epoch 8 Loss 1.650571\n",
      "Time taken for 1 epoch 251.1363935470581 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 1.0274\n",
      "Epoch 9 Batch 100 Loss 1.0109\n",
      "Epoch 9 Batch 200 Loss 1.0446\n",
      "Epoch 9 Batch 300 Loss 1.0336\n",
      "Epoch 9 Batch 400 Loss 1.1483\n",
      "Epoch 9 Batch 500 Loss 0.9660\n",
      "Epoch 9 Batch 600 Loss 0.9451\n",
      "Epoch 9 Batch 700 Loss 0.8301\n",
      "Epoch 9 Batch 800 Loss 1.0359\n",
      "Epoch 9 Batch 900 Loss 0.9434\n",
      "Epoch 9 Loss 1.576969\n",
      "Time taken for 1 epoch 251.16575241088867 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.9899\n",
      "Epoch 10 Batch 100 Loss 0.8815\n",
      "Epoch 10 Batch 200 Loss 0.8718\n",
      "Epoch 10 Batch 300 Loss 0.9638\n",
      "Epoch 10 Batch 400 Loss 0.9600\n",
      "Epoch 10 Batch 500 Loss 1.0525\n",
      "Epoch 10 Batch 600 Loss 0.8617\n",
      "Epoch 10 Batch 700 Loss 0.9269\n",
      "Epoch 10 Batch 800 Loss 0.8838\n",
      "Epoch 10 Batch 900 Loss 0.9465\n",
      "precision at | val: 0.17589285532633464, train: 0.2260928961748634\n",
      "Epoch 10 Loss 1.493817\n",
      "Time taken for 1 epoch 367.32783484458923 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.9181\n",
      "Epoch 11 Batch 100 Loss 0.8476\n",
      "Epoch 11 Batch 200 Loss 0.8366\n",
      "Epoch 11 Batch 300 Loss 0.9583\n",
      "Epoch 11 Batch 400 Loss 0.8797\n",
      "Epoch 11 Batch 500 Loss 0.9234\n",
      "Epoch 11 Batch 600 Loss 0.8691\n",
      "Epoch 11 Batch 700 Loss 0.8109\n",
      "Epoch 11 Batch 800 Loss 0.8700\n",
      "Epoch 11 Batch 900 Loss 0.7196\n",
      "Epoch 11 Loss 1.404249\n",
      "Time taken for 1 epoch 251.14300227165222 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.9138\n",
      "Epoch 12 Batch 100 Loss 0.8267\n",
      "Epoch 12 Batch 200 Loss 0.8857\n",
      "Epoch 12 Batch 300 Loss 0.8309\n",
      "Epoch 12 Batch 400 Loss 0.8238\n",
      "Epoch 12 Batch 500 Loss 0.8679\n",
      "Epoch 12 Batch 600 Loss 0.8600\n",
      "Epoch 12 Batch 700 Loss 0.6773\n",
      "Epoch 12 Batch 800 Loss 0.8504\n",
      "Epoch 12 Batch 900 Loss 0.9427\n",
      "Epoch 12 Loss 1.311289\n",
      "Time taken for 1 epoch 251.33302092552185 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.9271\n",
      "Epoch 13 Batch 100 Loss 0.6646\n",
      "Epoch 13 Batch 200 Loss 0.7360\n",
      "Epoch 13 Batch 300 Loss 0.7477\n",
      "Epoch 13 Batch 400 Loss 0.8627\n",
      "Epoch 13 Batch 500 Loss 0.6914\n",
      "Epoch 13 Batch 600 Loss 0.7667\n",
      "Epoch 13 Batch 700 Loss 0.6992\n",
      "Epoch 13 Batch 800 Loss 0.7410\n",
      "Epoch 13 Batch 900 Loss 0.8778\n",
      "precision at | val: 0.19, train: 0.28102230217938867\n",
      "Epoch 13 Loss 1.210114\n",
      "Time taken for 1 epoch 366.77834367752075 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.7255\n",
      "Epoch 14 Batch 100 Loss 0.6947\n",
      "Epoch 14 Batch 200 Loss 0.6959\n",
      "Epoch 14 Batch 300 Loss 0.6606\n",
      "Epoch 14 Batch 400 Loss 0.7080\n",
      "Epoch 14 Batch 500 Loss 0.6482\n",
      "Epoch 14 Batch 600 Loss 0.6342\n",
      "Epoch 14 Batch 700 Loss 0.8283\n",
      "Epoch 14 Batch 800 Loss 0.7146\n",
      "Epoch 14 Batch 900 Loss 0.7784\n",
      "Epoch 14 Loss 1.113205\n",
      "Time taken for 1 epoch 250.68508291244507 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.6313\n",
      "Epoch 15 Batch 100 Loss 0.6769\n",
      "Epoch 15 Batch 200 Loss 0.7059\n",
      "Epoch 15 Batch 300 Loss 0.6202\n",
      "Epoch 15 Batch 400 Loss 0.6978\n",
      "Epoch 15 Batch 500 Loss 0.7316\n",
      "Epoch 15 Batch 600 Loss 0.7692\n",
      "Epoch 15 Batch 700 Loss 0.5135\n",
      "Epoch 15 Batch 800 Loss 0.5651\n",
      "Epoch 15 Batch 900 Loss 0.6995\n",
      "Epoch 15 Loss 1.018736\n",
      "Time taken for 1 epoch 251.72885489463806 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.6911\n",
      "Epoch 16 Batch 100 Loss 0.6306\n",
      "Epoch 16 Batch 200 Loss 0.5688\n",
      "Epoch 16 Batch 300 Loss 0.5571\n",
      "Epoch 16 Batch 400 Loss 0.6228\n",
      "Epoch 16 Batch 500 Loss 0.5437\n",
      "Epoch 16 Batch 600 Loss 0.6631\n",
      "Epoch 16 Batch 700 Loss 0.6258\n",
      "Epoch 16 Batch 800 Loss 0.5421\n",
      "Epoch 16 Batch 900 Loss 0.6389\n",
      "precision at | val: 0.18648810068766275, train: 0.39139344262295084\n",
      "Epoch 16 Loss 0.931427\n",
      "Time taken for 1 epoch 368.2874643802643 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.5683\n",
      "Epoch 17 Batch 100 Loss 0.6138\n",
      "Epoch 17 Batch 200 Loss 0.5085\n",
      "Epoch 17 Batch 300 Loss 0.5168\n",
      "Epoch 17 Batch 400 Loss 0.5605\n",
      "Epoch 17 Batch 500 Loss 0.6006\n",
      "Epoch 17 Batch 600 Loss 0.5189\n",
      "Epoch 17 Batch 700 Loss 0.5980\n",
      "Epoch 17 Batch 800 Loss 0.6395\n",
      "Epoch 17 Batch 900 Loss 0.5220\n",
      "Epoch 17 Loss 0.848929\n",
      "Time taken for 1 epoch 251.1159222126007 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.4667\n",
      "Epoch 18 Batch 100 Loss 0.3819\n",
      "Epoch 18 Batch 200 Loss 0.5174\n",
      "Epoch 18 Batch 300 Loss 0.5612\n",
      "Epoch 18 Batch 400 Loss 0.4851\n",
      "Epoch 18 Batch 500 Loss 0.4614\n",
      "Epoch 18 Batch 600 Loss 0.4487\n",
      "Epoch 18 Batch 700 Loss 0.4389\n",
      "Epoch 18 Batch 800 Loss 0.4730\n",
      "Epoch 18 Batch 900 Loss 0.4375\n",
      "Epoch 18 Loss 0.777301\n",
      "Time taken for 1 epoch 250.9033784866333 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.4269\n",
      "Epoch 19 Batch 100 Loss 0.4761\n",
      "Epoch 19 Batch 200 Loss 0.4897\n",
      "Epoch 19 Batch 300 Loss 0.4298\n",
      "Epoch 19 Batch 400 Loss 0.5333\n",
      "Epoch 19 Batch 500 Loss 0.5140\n",
      "Epoch 19 Batch 600 Loss 0.4384\n",
      "Epoch 19 Batch 700 Loss 0.3607\n",
      "Epoch 19 Batch 800 Loss 0.3899\n",
      "Epoch 19 Batch 900 Loss 0.4032\n",
      "precision at | val: 0.13273810068766276, train: 0.5125455262231045\n",
      "Epoch 19 Loss 0.712627\n",
      "Time taken for 1 epoch 367.5591640472412 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.5028\n",
      "Epoch 20 Batch 100 Loss 0.4331\n",
      "Epoch 20 Batch 200 Loss 0.4206\n",
      "Epoch 20 Batch 300 Loss 0.3610\n",
      "Epoch 20 Batch 400 Loss 0.4401\n",
      "Epoch 20 Batch 500 Loss 0.3888\n",
      "Epoch 20 Batch 600 Loss 0.4562\n",
      "Epoch 20 Batch 700 Loss 0.4030\n",
      "Epoch 20 Batch 800 Loss 0.4322\n",
      "Epoch 20 Batch 900 Loss 0.4509\n",
      "Epoch 20 Loss 0.653001\n",
      "Time taken for 1 epoch 250.73567867279053 sec\n",
      "\n",
      "Epoch 21 Batch 0 Loss 0.3603\n",
      "Epoch 21 Batch 100 Loss 0.3195\n",
      "Epoch 21 Batch 200 Loss 0.3125\n",
      "Epoch 21 Batch 300 Loss 0.3489\n",
      "Epoch 21 Batch 400 Loss 0.4416\n",
      "Epoch 21 Batch 500 Loss 0.3592\n",
      "Epoch 21 Batch 600 Loss 0.3934\n",
      "Epoch 21 Batch 700 Loss 0.4115\n",
      "Epoch 21 Batch 800 Loss 0.4154\n",
      "Epoch 21 Batch 900 Loss 0.3273\n",
      "Epoch 21 Loss 0.606277\n",
      "Time taken for 1 epoch 251.72558164596558 sec\n",
      "\n",
      "Epoch 22 Batch 0 Loss 0.3685\n",
      "Epoch 22 Batch 100 Loss 0.2725\n",
      "Epoch 22 Batch 200 Loss 0.2878\n",
      "Epoch 22 Batch 300 Loss 0.4170\n",
      "Epoch 22 Batch 400 Loss 0.3832\n",
      "Epoch 22 Batch 500 Loss 0.3565\n",
      "Epoch 22 Batch 600 Loss 0.3389\n",
      "Epoch 22 Batch 700 Loss 0.3447\n",
      "Epoch 22 Batch 800 Loss 0.2615\n",
      "Epoch 22 Batch 900 Loss 0.3632\n",
      "precision at | val: 0.15416666666666667, train: 0.692133402172985\n",
      "Epoch 22 Loss 0.562141\n",
      "Time taken for 1 epoch 367.56548833847046 sec\n",
      "\n",
      "Epoch 23 Batch 0 Loss 0.4038\n",
      "Epoch 23 Batch 100 Loss 0.2671\n",
      "Epoch 23 Batch 200 Loss 0.3469\n",
      "Epoch 23 Batch 300 Loss 0.3084\n",
      "Epoch 23 Batch 400 Loss 0.2860\n",
      "Epoch 23 Batch 500 Loss 0.3333\n",
      "Epoch 23 Batch 600 Loss 0.3342\n",
      "Epoch 23 Batch 700 Loss 0.3627\n",
      "Epoch 23 Batch 800 Loss 0.3174\n",
      "Epoch 23 Batch 900 Loss 0.2833\n",
      "Epoch 23 Loss 0.519963\n",
      "Time taken for 1 epoch 250.7931351661682 sec\n",
      "\n",
      "Epoch 24 Batch 0 Loss 0.4487\n",
      "Epoch 24 Batch 100 Loss 0.3232\n",
      "Epoch 24 Batch 200 Loss 0.3009\n",
      "Epoch 24 Batch 300 Loss 0.3818\n",
      "Epoch 24 Batch 400 Loss 0.2869\n",
      "Epoch 24 Batch 500 Loss 0.3404\n",
      "Epoch 24 Batch 600 Loss 0.2663\n",
      "Epoch 24 Batch 700 Loss 0.3750\n",
      "Epoch 24 Batch 800 Loss 0.3301\n",
      "Epoch 24 Batch 900 Loss 0.3308\n",
      "Epoch 24 Loss 0.488426\n",
      "Time taken for 1 epoch 251.34087777137756 sec\n",
      "\n",
      "Epoch 25 Batch 0 Loss 0.3348\n",
      "Epoch 25 Batch 100 Loss 0.2943\n",
      "Epoch 25 Batch 200 Loss 0.2284\n",
      "Epoch 25 Batch 300 Loss 0.3439\n",
      "Epoch 25 Batch 400 Loss 0.2619\n",
      "Epoch 25 Batch 500 Loss 0.3374\n",
      "Epoch 25 Batch 600 Loss 0.2729\n",
      "Epoch 25 Batch 700 Loss 0.2262\n",
      "Epoch 25 Batch 800 Loss 0.2924\n",
      "Epoch 25 Batch 900 Loss 0.3306\n",
      "precision at | val: 0.1473214340209961, train: 0.8919171442751025\n",
      "Epoch 25 Loss 0.455380\n",
      "Time taken for 1 epoch 366.9537057876587 sec\n",
      "\n",
      "Epoch 26 Batch 0 Loss 0.2919\n",
      "Epoch 26 Batch 100 Loss 0.2713\n",
      "Epoch 26 Batch 200 Loss 0.2155\n",
      "Epoch 26 Batch 300 Loss 0.2667\n",
      "Epoch 26 Batch 400 Loss 0.2147\n",
      "Epoch 26 Batch 500 Loss 0.2551\n",
      "Epoch 26 Batch 600 Loss 0.2536\n",
      "Epoch 26 Batch 700 Loss 0.2593\n",
      "Epoch 26 Batch 800 Loss 0.2364\n",
      "Epoch 26 Batch 900 Loss 0.3261\n",
      "Epoch 26 Loss 0.430603\n",
      "Time taken for 1 epoch 251.52411341667175 sec\n",
      "\n",
      "Epoch 27 Batch 0 Loss 0.2147\n",
      "Epoch 27 Batch 100 Loss 0.1963\n",
      "Epoch 27 Batch 200 Loss 0.2387\n",
      "Epoch 27 Batch 300 Loss 0.2025\n",
      "Epoch 27 Batch 400 Loss 0.2271\n",
      "Epoch 27 Batch 500 Loss 0.2753\n",
      "Epoch 27 Batch 600 Loss 0.2539\n",
      "Epoch 27 Batch 700 Loss 0.1797\n",
      "Epoch 27 Batch 800 Loss 0.3077\n",
      "Epoch 27 Batch 900 Loss 0.3168\n",
      "Epoch 27 Loss 0.406859\n",
      "Time taken for 1 epoch 251.38033747673035 sec\n",
      "\n",
      "Epoch 28 Batch 0 Loss 0.2640\n",
      "Epoch 28 Batch 100 Loss 0.2244\n",
      "Epoch 28 Batch 200 Loss 0.2272\n",
      "Epoch 28 Batch 300 Loss 0.1929\n",
      "Epoch 28 Batch 400 Loss 0.2211\n",
      "Epoch 28 Batch 500 Loss 0.3054\n",
      "Epoch 28 Batch 600 Loss 0.1907\n",
      "Epoch 28 Batch 700 Loss 0.2214\n",
      "Epoch 28 Batch 800 Loss 0.2833\n",
      "Epoch 28 Batch 900 Loss 0.2566\n",
      "precision at | val: 0.14291666666666666, train: 1.0846311475409836\n",
      "Epoch 28 Loss 0.386148\n",
      "Time taken for 1 epoch 368.18407368659973 sec\n",
      "\n",
      "Epoch 29 Batch 0 Loss 0.3602\n",
      "Epoch 29 Batch 100 Loss 0.2299\n",
      "Epoch 29 Batch 200 Loss 0.1536\n",
      "Epoch 29 Batch 300 Loss 0.2364\n",
      "Epoch 29 Batch 400 Loss 0.3164\n",
      "Epoch 29 Batch 500 Loss 0.2530\n",
      "Epoch 29 Batch 600 Loss 0.1812\n",
      "Epoch 29 Batch 700 Loss 0.1632\n",
      "Epoch 29 Batch 800 Loss 0.3008\n",
      "Epoch 29 Batch 900 Loss 0.2164\n",
      "Epoch 29 Loss 0.365220\n",
      "Time taken for 1 epoch 250.6438844203949 sec\n",
      "\n",
      "Epoch 30 Batch 0 Loss 0.2503\n",
      "Epoch 30 Batch 100 Loss 0.2441\n",
      "Epoch 30 Batch 200 Loss 0.2968\n",
      "Epoch 30 Batch 300 Loss 0.1908\n",
      "Epoch 30 Batch 400 Loss 0.2027\n",
      "Epoch 30 Batch 500 Loss 0.2686\n",
      "Epoch 30 Batch 600 Loss 0.1925\n",
      "Epoch 30 Batch 700 Loss 0.3090\n",
      "Epoch 30 Batch 800 Loss 0.2084\n",
      "Epoch 30 Batch 900 Loss 0.2154\n",
      "Epoch 30 Loss 0.350424\n",
      "Time taken for 1 epoch 251.35500049591064 sec\n",
      "\n",
      "Epoch 31 Batch 0 Loss 0.2061\n",
      "Epoch 31 Batch 100 Loss 0.1782\n",
      "Epoch 31 Batch 200 Loss 0.2040\n",
      "Epoch 31 Batch 300 Loss 0.1857\n",
      "Epoch 31 Batch 400 Loss 0.2338\n",
      "Epoch 31 Batch 500 Loss 0.2255\n",
      "Epoch 31 Batch 600 Loss 0.1823\n",
      "Epoch 31 Batch 700 Loss 0.2341\n",
      "Epoch 31 Batch 800 Loss 0.1738\n",
      "Epoch 31 Batch 900 Loss 0.2376\n",
      "precision at | val: 0.13613095601399738, train: 1.2746243169398908\n",
      "Epoch 31 Loss 0.337925\n",
      "Time taken for 1 epoch 369.5576295852661 sec\n",
      "\n",
      "Epoch 32 Batch 0 Loss 0.1855\n",
      "Epoch 32 Batch 100 Loss 0.1975\n",
      "Epoch 32 Batch 200 Loss 0.2285\n",
      "Epoch 32 Batch 300 Loss 0.1541\n",
      "Epoch 32 Batch 400 Loss 0.1601\n",
      "Epoch 32 Batch 500 Loss 0.1647\n",
      "Epoch 32 Batch 600 Loss 0.1966\n",
      "Epoch 32 Batch 700 Loss 0.1483\n",
      "Epoch 32 Batch 800 Loss 0.2271\n",
      "Epoch 32 Batch 900 Loss 0.2278\n",
      "Epoch 32 Loss 0.322341\n",
      "Time taken for 1 epoch 251.67403554916382 sec\n",
      "\n",
      "Epoch 33 Batch 0 Loss 0.2837\n",
      "Epoch 33 Batch 100 Loss 0.2786\n",
      "Epoch 33 Batch 200 Loss 0.2121\n",
      "Epoch 33 Batch 300 Loss 0.2466\n",
      "Epoch 33 Batch 400 Loss 0.2117\n",
      "Epoch 33 Batch 500 Loss 0.2450\n",
      "Epoch 33 Batch 600 Loss 0.1767\n",
      "Epoch 33 Batch 700 Loss 0.2142\n",
      "Epoch 33 Batch 800 Loss 0.2069\n",
      "Epoch 33 Batch 900 Loss 0.1782\n",
      "Epoch 33 Loss 0.311157\n",
      "Time taken for 1 epoch 251.38014483451843 sec\n",
      "\n",
      "Epoch 34 Batch 0 Loss 0.2433\n",
      "Epoch 34 Batch 100 Loss 0.1653\n",
      "Epoch 34 Batch 200 Loss 0.1973\n",
      "Epoch 34 Batch 300 Loss 0.1674\n",
      "Epoch 34 Batch 400 Loss 0.1868\n",
      "Epoch 34 Batch 500 Loss 0.2034\n",
      "Epoch 34 Batch 600 Loss 0.1670\n",
      "Epoch 34 Batch 700 Loss 0.1616\n",
      "Epoch 34 Batch 800 Loss 0.2167\n",
      "Epoch 34 Batch 900 Loss 0.1716\n",
      "precision at | val: 0.12940476735432943, train: 1.3974043715846995\n",
      "Epoch 34 Loss 0.296833\n",
      "Time taken for 1 epoch 368.4289605617523 sec\n",
      "\n",
      "Epoch 35 Batch 0 Loss 0.1984\n",
      "Epoch 35 Batch 100 Loss 0.2481\n",
      "Epoch 35 Batch 200 Loss 0.1560\n",
      "Epoch 35 Batch 300 Loss 0.1515\n",
      "Epoch 35 Batch 400 Loss 0.1216\n",
      "Epoch 35 Batch 500 Loss 0.2561\n",
      "Epoch 35 Batch 600 Loss 0.1458\n",
      "Epoch 35 Batch 700 Loss 0.1880\n",
      "Epoch 35 Batch 800 Loss 0.1996\n",
      "Epoch 35 Batch 900 Loss 0.2024\n",
      "Epoch 35 Loss 0.282412\n",
      "Time taken for 1 epoch 251.20849084854126 sec\n",
      "\n",
      "Epoch 36 Batch 0 Loss 0.2374\n",
      "Epoch 36 Batch 100 Loss 0.1723\n",
      "Epoch 36 Batch 200 Loss 0.1191\n",
      "Epoch 36 Batch 300 Loss 0.1997\n",
      "Epoch 36 Batch 400 Loss 0.1325\n",
      "Epoch 36 Batch 500 Loss 0.1612\n",
      "Epoch 36 Batch 600 Loss 0.1955\n",
      "Epoch 36 Batch 700 Loss 0.1381\n",
      "Epoch 36 Batch 800 Loss 0.1300\n",
      "Epoch 36 Batch 900 Loss 0.1562\n",
      "Epoch 36 Loss 0.278813\n",
      "Time taken for 1 epoch 251.36125254631042 sec\n",
      "\n",
      "Epoch 37 Batch 0 Loss 0.2872\n",
      "Epoch 37 Batch 100 Loss 0.1131\n",
      "Epoch 37 Batch 200 Loss 0.1536\n",
      "Epoch 37 Batch 300 Loss 0.1081\n",
      "Epoch 37 Batch 400 Loss 0.1230\n",
      "Epoch 37 Batch 500 Loss 0.1864\n",
      "Epoch 37 Batch 600 Loss 0.1206\n",
      "Epoch 37 Batch 700 Loss 0.1935\n",
      "Epoch 37 Batch 800 Loss 0.2260\n",
      "Epoch 37 Batch 900 Loss 0.1554\n",
      "precision at | val: 0.13041666666666665, train: 1.536111066641052\n",
      "Epoch 37 Loss 0.270934\n",
      "Time taken for 1 epoch 369.35771107673645 sec\n",
      "\n",
      "Epoch 38 Batch 0 Loss 0.2080\n",
      "Epoch 38 Batch 100 Loss 0.1608\n",
      "Epoch 38 Batch 200 Loss 0.1325\n",
      "Epoch 38 Batch 300 Loss 0.1653\n",
      "Epoch 38 Batch 400 Loss 0.1572\n",
      "Epoch 38 Batch 500 Loss 0.1212\n",
      "Epoch 38 Batch 600 Loss 0.1865\n",
      "Epoch 38 Batch 700 Loss 0.2120\n",
      "Epoch 38 Batch 800 Loss 0.1583\n",
      "Epoch 38 Batch 900 Loss 0.1720\n",
      "Epoch 38 Loss 0.263564\n",
      "Time taken for 1 epoch 251.52005004882812 sec\n",
      "\n",
      "Epoch 39 Batch 0 Loss 0.1453\n",
      "Epoch 39 Batch 100 Loss 0.0814\n",
      "Epoch 39 Batch 200 Loss 0.2566\n",
      "Epoch 39 Batch 300 Loss 0.1288\n",
      "Epoch 39 Batch 400 Loss 0.1335\n",
      "Epoch 39 Batch 500 Loss 0.1055\n",
      "Epoch 39 Batch 600 Loss 0.1575\n",
      "Epoch 39 Batch 700 Loss 0.1975\n",
      "Epoch 39 Batch 800 Loss 0.1638\n",
      "Epoch 39 Batch 900 Loss 0.1822\n",
      "Epoch 39 Loss 0.256939\n",
      "Time taken for 1 epoch 251.2755765914917 sec\n",
      "\n",
      "Epoch 40 Batch 0 Loss 0.1719\n",
      "Epoch 40 Batch 100 Loss 0.1746\n",
      "Epoch 40 Batch 200 Loss 0.1302\n",
      "Epoch 40 Batch 300 Loss 0.1092\n",
      "Epoch 40 Batch 400 Loss 0.1334\n",
      "Epoch 40 Batch 500 Loss 0.1815\n",
      "Epoch 40 Batch 600 Loss 0.1828\n",
      "Epoch 40 Batch 700 Loss 0.1503\n",
      "Epoch 40 Batch 800 Loss 0.1248\n",
      "Epoch 40 Batch 900 Loss 0.1206\n",
      "precision at | val: 0.1260714340209961, train: 1.648406148608265\n",
      "Epoch 40 Loss 0.250301\n",
      "Time taken for 1 epoch 368.48011112213135 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "looper.train(dataset_train, dataset_val, 40, save_n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 0.1788\n",
      "Epoch 1 Batch 100 Loss 0.1774\n",
      "Epoch 1 Batch 200 Loss 0.1125\n",
      "Epoch 1 Batch 300 Loss 0.1337\n",
      "Epoch 1 Batch 400 Loss 0.1531\n",
      "Epoch 1 Batch 500 Loss 0.1407\n",
      "Epoch 1 Batch 600 Loss 0.1216\n",
      "Epoch 1 Batch 700 Loss 0.2066\n",
      "Epoch 1 Batch 800 Loss 0.1057\n",
      "Epoch 1 Batch 900 Loss 0.1820\n",
      "precision at | val: 0.12833333333333333, train: 1.6742486338797815\n",
      "Epoch 1 Loss 0.241029\n",
      "Time taken for 1 epoch 368.7309670448303 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.1843\n",
      "Epoch 2 Batch 100 Loss 0.1414\n",
      "Epoch 2 Batch 200 Loss 0.1635\n",
      "Epoch 2 Batch 300 Loss 0.1373\n",
      "Epoch 2 Batch 400 Loss 0.1497\n",
      "Epoch 2 Batch 500 Loss 0.1318\n",
      "Epoch 2 Batch 600 Loss 0.1662\n",
      "Epoch 2 Batch 700 Loss 0.1286\n",
      "Epoch 2 Batch 800 Loss 0.1474\n",
      "Epoch 2 Batch 900 Loss 0.1637\n",
      "Epoch 2 Loss 0.234149\n",
      "Time taken for 1 epoch 250.77812337875366 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.2334\n",
      "Epoch 3 Batch 100 Loss 0.1049\n",
      "Epoch 3 Batch 200 Loss 0.1185\n",
      "Epoch 3 Batch 300 Loss 0.1631\n",
      "Epoch 3 Batch 400 Loss 0.1774\n",
      "Epoch 3 Batch 500 Loss 0.1638\n",
      "Epoch 3 Batch 600 Loss 0.1825\n",
      "Epoch 3 Batch 700 Loss 0.2080\n",
      "Epoch 3 Batch 800 Loss 0.0901\n",
      "Epoch 3 Batch 900 Loss 0.1858\n",
      "Epoch 3 Loss 0.231459\n",
      "Time taken for 1 epoch 251.65006494522095 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.1373\n",
      "Epoch 4 Batch 100 Loss 0.1122\n",
      "Epoch 4 Batch 200 Loss 0.1128\n",
      "Epoch 4 Batch 300 Loss 0.1075\n",
      "Epoch 4 Batch 400 Loss 0.1132\n",
      "Epoch 4 Batch 500 Loss 0.1870\n",
      "Epoch 4 Batch 600 Loss 0.0955\n",
      "Epoch 4 Batch 700 Loss 0.1583\n",
      "Epoch 4 Batch 800 Loss 0.1205\n",
      "Epoch 4 Batch 900 Loss 0.1198\n",
      "precision at | val: 0.14714285532633464, train: 1.7641280043971994\n",
      "Epoch 4 Loss 0.227222\n",
      "Time taken for 1 epoch 367.8784031867981 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.1525\n",
      "Epoch 5 Batch 100 Loss 0.1986\n",
      "Epoch 5 Batch 200 Loss 0.1305\n",
      "Epoch 5 Batch 300 Loss 0.1072\n",
      "Epoch 5 Batch 400 Loss 0.1936\n",
      "Epoch 5 Batch 500 Loss 0.1041\n",
      "Epoch 5 Batch 600 Loss 0.1311\n",
      "Epoch 5 Batch 700 Loss 0.1311\n",
      "Epoch 5 Batch 800 Loss 0.1058\n",
      "Epoch 5 Batch 900 Loss 0.1274\n",
      "Epoch 5 Loss 0.222777\n",
      "Time taken for 1 epoch 251.10218286514282 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.1499\n",
      "Epoch 6 Batch 100 Loss 0.1964\n",
      "Epoch 6 Batch 200 Loss 0.0801\n",
      "Epoch 6 Batch 300 Loss 0.2874\n",
      "Epoch 6 Batch 400 Loss 0.1080\n",
      "Epoch 6 Batch 500 Loss 0.1181\n",
      "Epoch 6 Batch 600 Loss 0.1556\n",
      "Epoch 6 Batch 700 Loss 0.1171\n",
      "Epoch 6 Batch 800 Loss 0.1571\n",
      "Epoch 6 Batch 900 Loss 0.1323\n",
      "Epoch 6 Loss 0.214129\n",
      "Time taken for 1 epoch 251.06428933143616 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.1653\n",
      "Epoch 7 Batch 100 Loss 0.1507\n",
      "Epoch 7 Batch 200 Loss 0.1527\n",
      "Epoch 7 Batch 300 Loss 0.1354\n",
      "Epoch 7 Batch 400 Loss 0.1117\n",
      "Epoch 7 Batch 500 Loss 0.1591\n",
      "Epoch 7 Batch 600 Loss 0.1481\n",
      "Epoch 7 Batch 700 Loss 0.1883\n",
      "Epoch 7 Batch 800 Loss 0.1590\n",
      "Epoch 7 Batch 900 Loss 0.0895\n",
      "precision at | val: 0.12714285532633463, train: 1.8553620218579234\n",
      "Epoch 7 Loss 0.213068\n",
      "Time taken for 1 epoch 367.57677483558655 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.1828\n",
      "Epoch 8 Batch 100 Loss 0.1076\n",
      "Epoch 8 Batch 200 Loss 0.1621\n",
      "Epoch 8 Batch 300 Loss 0.2067\n",
      "Epoch 8 Batch 400 Loss 0.1869\n",
      "Epoch 8 Batch 500 Loss 0.1397\n",
      "Epoch 8 Batch 600 Loss 0.2083\n",
      "Epoch 8 Batch 700 Loss 0.1217\n",
      "Epoch 8 Batch 800 Loss 0.1328\n",
      "Epoch 8 Batch 900 Loss 0.1547\n",
      "Epoch 8 Loss 0.214318\n",
      "Time taken for 1 epoch 251.63142585754395 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.1678\n",
      "Epoch 9 Batch 100 Loss 0.0604\n",
      "Epoch 9 Batch 200 Loss 0.1330\n",
      "Epoch 9 Batch 300 Loss 0.0993\n",
      "Epoch 9 Batch 400 Loss 0.1877\n",
      "Epoch 9 Batch 500 Loss 0.1031\n",
      "Epoch 9 Batch 600 Loss 0.1817\n",
      "Epoch 9 Batch 700 Loss 0.1612\n",
      "Epoch 9 Batch 800 Loss 0.1131\n",
      "Epoch 9 Batch 900 Loss 0.1104\n",
      "Epoch 9 Loss 0.203813\n",
      "Time taken for 1 epoch 251.17604184150696 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.1900\n",
      "Epoch 10 Batch 100 Loss 0.0664\n",
      "Epoch 10 Batch 200 Loss 0.0559\n",
      "Epoch 10 Batch 300 Loss 0.1072\n",
      "Epoch 10 Batch 400 Loss 0.1017\n",
      "Epoch 10 Batch 500 Loss 0.0949\n",
      "Epoch 10 Batch 600 Loss 0.0906\n",
      "Epoch 10 Batch 700 Loss 0.1759\n",
      "Epoch 10 Batch 800 Loss 0.1681\n",
      "Epoch 10 Batch 900 Loss 0.0909\n",
      "precision at | val: 0.1500595219930013, train: 1.9400728152749316\n",
      "Epoch 10 Loss 0.199970\n",
      "Time taken for 1 epoch 367.3026306629181 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.1158\n",
      "Epoch 11 Batch 100 Loss 0.1096\n",
      "Epoch 11 Batch 200 Loss 0.1324\n",
      "Epoch 11 Batch 300 Loss 0.0689\n",
      "Epoch 11 Batch 400 Loss 0.1342\n",
      "Epoch 11 Batch 500 Loss 0.0939\n",
      "Epoch 11 Batch 600 Loss 0.1263\n",
      "Epoch 11 Batch 700 Loss 0.0503\n",
      "Epoch 11 Batch 800 Loss 0.1296\n",
      "Epoch 11 Batch 900 Loss 0.1364\n",
      "Epoch 11 Loss 0.199528\n",
      "Time taken for 1 epoch 251.0098192691803 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.1394\n",
      "Epoch 12 Batch 100 Loss 0.1622\n",
      "Epoch 12 Batch 200 Loss 0.1190\n",
      "Epoch 12 Batch 300 Loss 0.0910\n",
      "Epoch 12 Batch 400 Loss 0.0872\n",
      "Epoch 12 Batch 500 Loss 0.0961\n",
      "Epoch 12 Batch 600 Loss 0.1537\n",
      "Epoch 12 Batch 700 Loss 0.1174\n",
      "Epoch 12 Batch 800 Loss 0.1217\n",
      "Epoch 12 Batch 900 Loss 0.1647\n",
      "Epoch 12 Loss 0.193914\n",
      "Time taken for 1 epoch 251.1619737148285 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.1754\n",
      "Epoch 13 Batch 100 Loss 0.0742\n",
      "Epoch 13 Batch 200 Loss 0.0784\n",
      "Epoch 13 Batch 300 Loss 0.1445\n",
      "Epoch 13 Batch 400 Loss 0.0980\n",
      "Epoch 13 Batch 500 Loss 0.0871\n",
      "Epoch 13 Batch 600 Loss 0.1600\n",
      "Epoch 13 Batch 700 Loss 0.0682\n",
      "Epoch 13 Batch 800 Loss 0.0976\n",
      "Epoch 13 Batch 900 Loss 0.0936\n",
      "precision at | val: 0.15035714467366537, train: 1.937568306010929\n",
      "Epoch 13 Loss 0.190745\n",
      "Time taken for 1 epoch 368.23306584358215 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.0846\n",
      "Epoch 14 Batch 100 Loss 0.0874\n",
      "Epoch 14 Batch 200 Loss 0.1130\n",
      "Epoch 14 Batch 300 Loss 0.1093\n",
      "Epoch 14 Batch 400 Loss 0.1198\n",
      "Epoch 14 Batch 500 Loss 0.1161\n",
      "Epoch 14 Batch 600 Loss 0.0957\n",
      "Epoch 14 Batch 700 Loss 0.1118\n",
      "Epoch 14 Batch 800 Loss 0.1669\n",
      "Epoch 14 Batch 900 Loss 0.1005\n",
      "Epoch 14 Loss 0.190793\n",
      "Time taken for 1 epoch 251.3701946735382 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.1195\n",
      "Epoch 15 Batch 100 Loss 0.1050\n",
      "Epoch 15 Batch 200 Loss 0.1171\n",
      "Epoch 15 Batch 300 Loss 0.1287\n",
      "Epoch 15 Batch 400 Loss 0.1279\n",
      "Epoch 15 Batch 500 Loss 0.1638\n",
      "Epoch 15 Batch 600 Loss 0.1868\n",
      "Epoch 15 Batch 700 Loss 0.1615\n",
      "Epoch 15 Batch 800 Loss 0.1135\n",
      "Epoch 15 Batch 900 Loss 0.1520\n",
      "Epoch 15 Loss 0.188033\n",
      "Time taken for 1 epoch 251.195485830307 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.1554\n",
      "Epoch 16 Batch 100 Loss 0.0865\n",
      "Epoch 16 Batch 200 Loss 0.0780\n",
      "Epoch 16 Batch 300 Loss 0.1075\n",
      "Epoch 16 Batch 400 Loss 0.1154\n",
      "Epoch 16 Batch 500 Loss 0.1373\n",
      "Epoch 16 Batch 600 Loss 0.0918\n",
      "Epoch 16 Batch 700 Loss 0.1756\n",
      "Epoch 16 Batch 800 Loss 0.1058\n",
      "Epoch 16 Batch 900 Loss 0.1093\n",
      "precision at | val: 0.14815476735432942, train: 2.001047403304303\n",
      "Epoch 16 Loss 0.186149\n",
      "Time taken for 1 epoch 369.07190227508545 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.1492\n",
      "Epoch 17 Batch 100 Loss 0.1067\n",
      "Epoch 17 Batch 200 Loss 0.0674\n",
      "Epoch 17 Batch 300 Loss 0.1135\n",
      "Epoch 17 Batch 400 Loss 0.0971\n",
      "Epoch 17 Batch 500 Loss 0.0965\n",
      "Epoch 17 Batch 600 Loss 0.1004\n",
      "Epoch 17 Batch 700 Loss 0.1200\n",
      "Epoch 17 Batch 800 Loss 0.0838\n",
      "Epoch 17 Batch 900 Loss 0.0975\n",
      "Epoch 17 Loss 0.182107\n",
      "Time taken for 1 epoch 251.00690078735352 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.1181\n",
      "Epoch 18 Batch 100 Loss 0.1481\n",
      "Epoch 18 Batch 200 Loss 0.1097\n",
      "Epoch 18 Batch 300 Loss 0.1567\n",
      "Epoch 18 Batch 400 Loss 0.1248\n",
      "Epoch 18 Batch 500 Loss 0.0959\n",
      "Epoch 18 Batch 600 Loss 0.1049\n",
      "Epoch 18 Batch 700 Loss 0.1069\n",
      "Epoch 18 Batch 800 Loss 0.1011\n",
      "Epoch 18 Batch 900 Loss 0.0828\n",
      "Epoch 18 Loss 0.182640\n",
      "Time taken for 1 epoch 251.56729817390442 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.1051\n",
      "Epoch 19 Batch 100 Loss 0.0834\n",
      "Epoch 19 Batch 200 Loss 0.0632\n",
      "Epoch 19 Batch 300 Loss 0.1688\n",
      "Epoch 19 Batch 400 Loss 0.1288\n",
      "Epoch 19 Batch 500 Loss 0.0998\n",
      "Epoch 19 Batch 600 Loss 0.0883\n",
      "Epoch 19 Batch 700 Loss 0.1366\n",
      "Epoch 19 Batch 800 Loss 0.1136\n",
      "Epoch 19 Batch 900 Loss 0.0891\n",
      "precision at | val: 0.13398810068766276, train: 1.992156148608265\n",
      "Epoch 19 Loss 0.176360\n",
      "Time taken for 1 epoch 368.1283257007599 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.1796\n",
      "Epoch 20 Batch 100 Loss 0.1389\n",
      "Epoch 20 Batch 200 Loss 0.1579\n",
      "Epoch 20 Batch 300 Loss 0.1262\n",
      "Epoch 20 Batch 400 Loss 0.1065\n",
      "Epoch 20 Batch 500 Loss 0.1435\n",
      "Epoch 20 Batch 600 Loss 0.1106\n",
      "Epoch 20 Batch 700 Loss 0.1509\n",
      "Epoch 20 Batch 800 Loss 0.1006\n",
      "Epoch 20 Batch 900 Loss 0.0795\n",
      "Epoch 20 Loss 0.178096\n",
      "Time taken for 1 epoch 251.15591597557068 sec\n",
      "\n",
      "Epoch 21 Batch 0 Loss 0.1512\n",
      "Epoch 21 Batch 100 Loss 0.0963\n",
      "Epoch 21 Batch 200 Loss 0.1187\n",
      "Epoch 21 Batch 300 Loss 0.0535\n",
      "Epoch 21 Batch 400 Loss 0.1029\n",
      "Epoch 21 Batch 500 Loss 0.1081\n",
      "Epoch 21 Batch 600 Loss 0.1230\n",
      "Epoch 21 Batch 700 Loss 0.1212\n",
      "Epoch 21 Batch 800 Loss 0.1228\n",
      "Epoch 21 Batch 900 Loss 0.0916\n",
      "Epoch 21 Loss 0.170849\n",
      "Time taken for 1 epoch 251.5946981906891 sec\n",
      "\n",
      "Epoch 22 Batch 0 Loss 0.0950\n",
      "Epoch 22 Batch 100 Loss 0.0942\n",
      "Epoch 22 Batch 200 Loss 0.0807\n",
      "Epoch 22 Batch 300 Loss 0.1487\n",
      "Epoch 22 Batch 400 Loss 0.1001\n",
      "Epoch 22 Batch 500 Loss 0.0833\n",
      "Epoch 22 Batch 600 Loss 0.1027\n",
      "Epoch 22 Batch 700 Loss 0.0585\n",
      "Epoch 22 Batch 800 Loss 0.0911\n",
      "Epoch 22 Batch 900 Loss 0.0571\n",
      "precision at | val: 0.13166666666666665, train: 2.033743169398907\n",
      "Epoch 22 Loss 0.174370\n",
      "Time taken for 1 epoch 368.0225827693939 sec\n",
      "\n",
      "Epoch 23 Batch 0 Loss 0.1283\n",
      "Epoch 23 Batch 100 Loss 0.1428\n",
      "Epoch 23 Batch 200 Loss 0.0769\n",
      "Epoch 23 Batch 300 Loss 0.1418\n",
      "Epoch 23 Batch 400 Loss 0.1814\n",
      "Epoch 23 Batch 500 Loss 0.1401\n",
      "Epoch 23 Batch 600 Loss 0.0747\n",
      "Epoch 23 Batch 700 Loss 0.1438\n",
      "Epoch 23 Batch 800 Loss 0.2209\n",
      "Epoch 23 Batch 900 Loss 0.1142\n",
      "Epoch 23 Loss 0.176881\n",
      "Time taken for 1 epoch 250.502028465271 sec\n",
      "\n",
      "Epoch 24 Batch 0 Loss 0.0970\n",
      "Epoch 24 Batch 100 Loss 0.1146\n",
      "Epoch 24 Batch 200 Loss 0.1271\n",
      "Epoch 24 Batch 300 Loss 0.1658\n",
      "Epoch 24 Batch 400 Loss 0.1064\n",
      "Epoch 24 Batch 500 Loss 0.0480\n",
      "Epoch 24 Batch 600 Loss 0.1160\n",
      "Epoch 24 Batch 700 Loss 0.0797\n",
      "Epoch 24 Batch 800 Loss 0.0914\n",
      "Epoch 24 Batch 900 Loss 0.1074\n",
      "Epoch 24 Loss 0.167778\n",
      "Time taken for 1 epoch 250.88752555847168 sec\n",
      "\n",
      "Epoch 25 Batch 0 Loss 0.1011\n",
      "Epoch 25 Batch 100 Loss 0.0791\n",
      "Epoch 25 Batch 200 Loss 0.1234\n",
      "Epoch 25 Batch 300 Loss 0.1377\n",
      "Epoch 25 Batch 400 Loss 0.0634\n",
      "Epoch 25 Batch 500 Loss 0.1037\n",
      "Epoch 25 Batch 600 Loss 0.0874\n",
      "Epoch 25 Batch 700 Loss 0.1144\n",
      "Epoch 25 Batch 800 Loss 0.0926\n",
      "Epoch 25 Batch 900 Loss 0.0862\n",
      "precision at | val: 0.1325, train: 2.0518784153005463\n",
      "Epoch 25 Loss 0.168516\n",
      "Time taken for 1 epoch 368.4055995941162 sec\n",
      "\n",
      "Epoch 26 Batch 0 Loss 0.1164\n",
      "Epoch 26 Batch 100 Loss 0.0615\n",
      "Epoch 26 Batch 200 Loss 0.0755\n",
      "Epoch 26 Batch 300 Loss 0.0798\n",
      "Epoch 26 Batch 400 Loss 0.0585\n",
      "Epoch 26 Batch 500 Loss 0.0952\n",
      "Epoch 26 Batch 600 Loss 0.0521\n",
      "Epoch 26 Batch 700 Loss 0.0885\n",
      "Epoch 26 Batch 800 Loss 0.1078\n",
      "Epoch 26 Batch 900 Loss 0.0860\n",
      "Epoch 26 Loss 0.164433\n",
      "Time taken for 1 epoch 250.35980653762817 sec\n",
      "\n",
      "Epoch 27 Batch 0 Loss 0.1127\n",
      "Epoch 27 Batch 100 Loss 0.0869\n",
      "Epoch 27 Batch 200 Loss 0.0444\n",
      "Epoch 27 Batch 300 Loss 0.1056\n",
      "Epoch 27 Batch 400 Loss 0.0998\n",
      "Epoch 27 Batch 500 Loss 0.0831\n",
      "Epoch 27 Batch 600 Loss 0.1468\n",
      "Epoch 27 Batch 700 Loss 0.0571\n",
      "Epoch 27 Batch 800 Loss 0.1283\n",
      "Epoch 27 Batch 900 Loss 0.0543\n",
      "Epoch 27 Loss 0.164926\n",
      "Time taken for 1 epoch 250.72215390205383 sec\n",
      "\n",
      "Epoch 28 Batch 0 Loss 0.1303\n",
      "Epoch 28 Batch 100 Loss 0.1402\n",
      "Epoch 28 Batch 200 Loss 0.0544\n",
      "Epoch 28 Batch 300 Loss 0.1311\n",
      "Epoch 28 Batch 400 Loss 0.0836\n",
      "Epoch 28 Batch 500 Loss 0.0823\n",
      "Epoch 28 Batch 600 Loss 0.0927\n",
      "Epoch 28 Batch 700 Loss 0.1121\n",
      "Epoch 28 Batch 800 Loss 0.1099\n",
      "Epoch 28 Batch 900 Loss 0.0882\n",
      "precision at | val: 0.14565476735432942, train: 2.078756830601093\n",
      "Epoch 28 Loss 0.161976\n",
      "Time taken for 1 epoch 368.24965023994446 sec\n",
      "\n",
      "Epoch 29 Batch 0 Loss 0.1083\n",
      "Epoch 29 Batch 100 Loss 0.1474\n",
      "Epoch 29 Batch 200 Loss 0.0754\n",
      "Epoch 29 Batch 300 Loss 0.0981\n",
      "Epoch 29 Batch 400 Loss 0.1132\n",
      "Epoch 29 Batch 500 Loss 0.1054\n",
      "Epoch 29 Batch 600 Loss 0.0928\n",
      "Epoch 29 Batch 700 Loss 0.0821\n",
      "Epoch 29 Batch 800 Loss 0.1236\n",
      "Epoch 29 Batch 900 Loss 0.0912\n",
      "Epoch 29 Loss 0.161446\n",
      "Time taken for 1 epoch 250.52147006988525 sec\n",
      "\n",
      "Epoch 30 Batch 0 Loss 0.1613\n",
      "Epoch 30 Batch 100 Loss 0.1096\n",
      "Epoch 30 Batch 200 Loss 0.1229\n",
      "Epoch 30 Batch 300 Loss 0.1054\n",
      "Epoch 30 Batch 400 Loss 0.1013\n",
      "Epoch 30 Batch 500 Loss 0.1031\n",
      "Epoch 30 Batch 600 Loss 0.0955\n",
      "Epoch 30 Batch 700 Loss 0.0719\n",
      "Epoch 30 Batch 800 Loss 0.1223\n",
      "Epoch 30 Batch 900 Loss 0.1656\n",
      "Epoch 30 Loss 0.163963\n",
      "Time taken for 1 epoch 250.51489973068237 sec\n",
      "\n",
      "Epoch 31 Batch 0 Loss 0.1188\n",
      "Epoch 31 Batch 100 Loss 0.0617\n",
      "Epoch 31 Batch 200 Loss 0.1186\n",
      "Epoch 31 Batch 300 Loss 0.0601\n",
      "Epoch 31 Batch 400 Loss 0.1208\n",
      "Epoch 31 Batch 500 Loss 0.0794\n",
      "Epoch 31 Batch 600 Loss 0.1297\n",
      "Epoch 31 Batch 700 Loss 0.0818\n",
      "Epoch 31 Batch 800 Loss 0.2045\n",
      "Epoch 31 Batch 900 Loss 0.1419\n",
      "precision at | val: 0.14089285532633464, train: 2.138023634947063\n",
      "Epoch 31 Loss 0.161268\n",
      "Time taken for 1 epoch 368.61516308784485 sec\n",
      "\n",
      "Epoch 32 Batch 0 Loss 0.0964\n",
      "Epoch 32 Batch 100 Loss 0.1658\n",
      "Epoch 32 Batch 200 Loss 0.0737\n",
      "Epoch 32 Batch 300 Loss 0.0649\n",
      "Epoch 32 Batch 400 Loss 0.0577\n",
      "Epoch 32 Batch 500 Loss 0.0908\n",
      "Epoch 32 Batch 600 Loss 0.1241\n",
      "Epoch 32 Batch 700 Loss 0.0639\n",
      "Epoch 32 Batch 800 Loss 0.1048\n",
      "Epoch 32 Batch 900 Loss 0.0922\n",
      "Epoch 32 Loss 0.157063\n",
      "Time taken for 1 epoch 250.57028079032898 sec\n",
      "\n",
      "Epoch 33 Batch 0 Loss 0.0776\n",
      "Epoch 33 Batch 100 Loss 0.0770\n",
      "Epoch 33 Batch 200 Loss 0.0572\n",
      "Epoch 33 Batch 300 Loss 0.0757\n",
      "Epoch 33 Batch 400 Loss 0.0947\n",
      "Epoch 33 Batch 500 Loss 0.1031\n",
      "Epoch 33 Batch 600 Loss 0.0636\n",
      "Epoch 33 Batch 700 Loss 0.1057\n",
      "Epoch 33 Batch 800 Loss 0.1109\n",
      "Epoch 33 Batch 900 Loss 0.0726\n",
      "Epoch 33 Loss 0.155878\n",
      "Time taken for 1 epoch 250.26972699165344 sec\n",
      "\n",
      "Epoch 34 Batch 0 Loss 0.0811\n",
      "Epoch 34 Batch 100 Loss 0.1077\n",
      "Epoch 34 Batch 200 Loss 0.0519\n",
      "Epoch 34 Batch 300 Loss 0.1035\n",
      "Epoch 34 Batch 400 Loss 0.1267\n",
      "Epoch 34 Batch 500 Loss 0.0689\n",
      "Epoch 34 Batch 600 Loss 0.1073\n",
      "Epoch 34 Batch 700 Loss 0.0740\n",
      "Epoch 34 Batch 800 Loss 0.1739\n",
      "Epoch 34 Batch 900 Loss 0.0442\n",
      "precision at | val: 0.14875, train: 2.116006419697746\n",
      "Epoch 34 Loss 0.158140\n",
      "Time taken for 1 epoch 366.6751244068146 sec\n",
      "\n",
      "Epoch 35 Batch 0 Loss 0.1888\n",
      "Epoch 35 Batch 100 Loss 0.0930\n",
      "Epoch 35 Batch 200 Loss 0.0986\n",
      "Epoch 35 Batch 300 Loss 0.1529\n",
      "Epoch 35 Batch 400 Loss 0.0732\n",
      "Epoch 35 Batch 500 Loss 0.1211\n",
      "Epoch 35 Batch 600 Loss 0.1222\n",
      "Epoch 35 Batch 700 Loss 0.0793\n",
      "Epoch 35 Batch 800 Loss 0.1142\n",
      "Epoch 35 Batch 900 Loss 0.0793\n",
      "Epoch 35 Loss 0.158758\n",
      "Time taken for 1 epoch 250.25383067131042 sec\n",
      "\n",
      "Epoch 36 Batch 0 Loss 0.0592\n",
      "Epoch 36 Batch 100 Loss 0.0847\n",
      "Epoch 36 Batch 200 Loss 0.0967\n",
      "Epoch 36 Batch 300 Loss 0.0789\n",
      "Epoch 36 Batch 400 Loss 0.0578\n",
      "Epoch 36 Batch 500 Loss 0.1357\n",
      "Epoch 36 Batch 600 Loss 0.1130\n",
      "Epoch 36 Batch 700 Loss 0.1472\n",
      "Epoch 36 Batch 800 Loss 0.0920\n",
      "Epoch 36 Batch 900 Loss 0.1546\n",
      "Epoch 36 Loss 0.153391\n",
      "Time taken for 1 epoch 251.5833764076233 sec\n",
      "\n",
      "Epoch 37 Batch 0 Loss 0.1166\n",
      "Epoch 37 Batch 100 Loss 0.1110\n",
      "Epoch 37 Batch 200 Loss 0.1456\n",
      "Epoch 37 Batch 300 Loss 0.1018\n",
      "Epoch 37 Batch 400 Loss 0.0741\n",
      "Epoch 37 Batch 500 Loss 0.1952\n",
      "Epoch 37 Batch 600 Loss 0.0876\n",
      "Epoch 37 Batch 700 Loss 0.0812\n",
      "Epoch 37 Batch 800 Loss 0.1176\n",
      "Epoch 37 Batch 900 Loss 0.0672\n",
      "precision at | val: 0.14416666666666667, train: 2.15094494428791\n",
      "Epoch 37 Loss 0.145987\n",
      "Time taken for 1 epoch 366.82666635513306 sec\n",
      "\n",
      "Epoch 38 Batch 0 Loss 0.1190\n",
      "Epoch 38 Batch 100 Loss 0.0644\n",
      "Epoch 38 Batch 200 Loss 0.1402\n",
      "Epoch 38 Batch 300 Loss 0.0301\n",
      "Epoch 38 Batch 400 Loss 0.1310\n",
      "Epoch 38 Batch 500 Loss 0.0486\n",
      "Epoch 38 Batch 600 Loss 0.0929\n",
      "Epoch 38 Batch 700 Loss 0.1138\n",
      "Epoch 38 Batch 800 Loss 0.1090\n",
      "Epoch 38 Batch 900 Loss 0.0442\n",
      "Epoch 38 Loss 0.153129\n",
      "Time taken for 1 epoch 251.141916513443 sec\n",
      "\n",
      "Epoch 39 Batch 0 Loss 0.0979\n",
      "Epoch 39 Batch 100 Loss 0.0913\n",
      "Epoch 39 Batch 200 Loss 0.1480\n",
      "Epoch 39 Batch 300 Loss 0.0453\n",
      "Epoch 39 Batch 400 Loss 0.1005\n",
      "Epoch 39 Batch 500 Loss 0.1689\n",
      "Epoch 39 Batch 600 Loss 0.1261\n",
      "Epoch 39 Batch 700 Loss 0.1099\n",
      "Epoch 39 Batch 800 Loss 0.0784\n",
      "Epoch 39 Batch 900 Loss 0.0936\n",
      "Epoch 39 Loss 0.152971\n",
      "Time taken for 1 epoch 251.34604620933533 sec\n",
      "\n",
      "Epoch 40 Batch 0 Loss 0.1479\n",
      "Epoch 40 Batch 100 Loss 0.0495\n",
      "Epoch 40 Batch 200 Loss 0.0985\n",
      "Epoch 40 Batch 300 Loss 0.2478\n",
      "Epoch 40 Batch 400 Loss 0.1438\n",
      "Epoch 40 Batch 500 Loss 0.0798\n",
      "Epoch 40 Batch 600 Loss 0.0833\n",
      "Epoch 40 Batch 700 Loss 0.0665\n",
      "Epoch 40 Batch 800 Loss 0.0970\n",
      "Epoch 40 Batch 900 Loss 0.0926\n",
      "precision at | val: 0.14839285532633464, train: 2.1478028677851775\n",
      "Epoch 40 Loss 0.148440\n",
      "Time taken for 1 epoch 368.76572489738464 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "looper.train(dataset_train, dataset_val, 40, save_n=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
